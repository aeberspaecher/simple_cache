#!/usr/bin/env python
#-*- coding:utf-8 -*-

"""Simple caching functionality using decorated functions.

Cached values are stored in a dicitonary. The keys are generated by a callable
given to the decorator. This can e.g. be used to cache expensive calculations
that depend on an object's state. In that case, the key generating-function
needs to be made aware of all relevant state attributes.
"""

# TODO: testing concept?

from functools import wraps

cache_registry = []


class NotInCacheError(Exception):
    """Exception to be thrown when a key that is not present in cache is read.
    """

    pass


class Cache(object):
    """Base class for caches.
    """

    def get(self, key):
        """Get a cached value from key.

        Parameters
        ----------
        key : string

        Raises
        ------
        NotInCacheError
            In case key does not exist in cache.
        """
        raise NotImplementedError()

    def set(self, key, value):
        """Set a key/value pair in cache.

        Parameters
        ----------
        key : string
        value : object
        """
        raise NotImplementedError()

    def clear(self):
        """Clean out all cached items.
        """

        raise NotImplementedError()

    @property
    def keys(self):
        """Keys stored.
        """

        raise NotImplementedError()

    # TODO: is it reasonable to add a keys member, a delete() function?


class FiniteCache(Cache):
    """Implements a cache that can only hold a given number of elements.

    Uses a dict, but watches out for the number of keys in dict. If the maximum
    size is reached, the oldest key/value pair needs to go. This can be used
    for computations that return large objects.
    """

    def __init__(self, max_size):
        """Create a cacher that behaves much like a dictionary with a finite
        number of entries.

        Parameters
        ----------
        max_size : int
            Maximum number of entries.
        """

        self.max_size = max_size
        self.cache = {}  # dicts are not ordered, so...
        self.keys_in_order = []  # lists are ordered!

    def get(self, key):
        """Get a cached value from key.

        Parameters
        ----------
        key : string

        Raises
        ------
        NotInCacheError
            In case key does not exist in cache.
        """

        try:
            cached_val = self.cache[key]
            return cached_val
        except KeyError:
            raise NotInCacheError

    def set(self, key, value):
        """Set a key/value pair in cache.

        Parameters
        ----------
        key : string
        value : object
        """

        self.keys_in_order.append(key)
        self.cache[key] = value

        # if cache has grown too big (i.e. has too many cached items): clean
        # out oldest cached item
        if len(self.cache) > self.max_size:
            oldest_key = self.keys_in_order[0]  # first item is oldest key
            self.cache.pop(oldest_key)
            self.keys_in_order.pop(0)

    def clear(self):
        """Clean out all cached items.
        """

        self.cache.clear()
        for key in self.keys_in_order:
            del key
        self.keys_in_order = []

    @property
    def keys(self):
        return self.cache.keys()


def cacher(key_template=None, get_cacher=lambda: FiniteCache(5)):
    """Decorator that wraps a class member function with caching capabilities.

    Parameters
    ----------
    key_template : string
        A string that describes the class' state at runtime. The string needs
        to be such that .format() could be called on it.
    get_cache : callable, optional
        A callable to return an object with get(), set() and clear() methods.
        Default to `lambda: FiniteCache(5)`. The callable approach is used to
        ensure caches will be local to each decorated function.
    """

    if key_template is None:
        raise ValueError("A key_template must be given")

    cache = get_cacher()
    cache_registry.append(cache)
    # TODO: can we always do that? what a the requirements for this to work?
    # is a common interface enough?

    def decorate(func):
        func_name = func.__repr__()

        @wraps(func)
        def wrapper(*args, **kwargs):
            # bare-metal convert all positional arguments to keyword arguments:
            kwargs.update(dict(zip(func.func_code.co_varnames, args)))

            key = (func_name + "_"  # make cacher aware of function name
                   + key_template.format(**kwargs)  # evaluate key
                  )
            try:
                ret = cache.get(key)
            except NotInCacheError:
                ret = func(**kwargs)
                # TODO: call like that or use previously generated copy of kwargs together with args?
                cache.set(key, ret)

            return ret

        return wrapper

    return decorate


def clear_all_registered_caches():
    """Clear all caches registered.
    """

    for cache in cache_registry:
        cache.clear()
